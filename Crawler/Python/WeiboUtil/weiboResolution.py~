#!/bin/python
# FileName : weiboResolution.py
# -*- coding: utf-8 -*-

import cookielib
import urllib
import urllib2
import pyquery
import logging
import time
import random
import sys
from lxml import etree

logging.basicConfig(level=logging.DEBUG,format='%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s',datefmt='%a, %d %b %Y %H:%M:%S',stream=sys.stdout) 



class BlockedException(Exception):
    def __init__(self):
        Exception.__init__(self)

class weiboResolution:
    def __init__(self,username,password):
        self.username=username
        self.password=password
           ''' try: 
                #login and build opener with cookie
                self.opener=self.login()
            except urllib2.HTTPError as e:
                print e
                exit()
            except Exception as e:
                print e
                exit()'''

     def login(self):
        #create cookie
        cookieJ = cookielib.CookieJar()
        #install cookie
        opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookieJ))
        #pretend to be a browser
        opener.addheaders=[('User-Agent','Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.65 Safari/537.36')]
        #open login page
        response=opener.open('http://login.weibo.cn/login/')
        loginText=response.read()
        Pyquery=pyquery.PyQuery(loginText)
        #get login url
        loginURL=Pyquery('form').attr('action')
        loginURL='http://login.weibo.cn/login/'+loginURL
	tree=etree.HTML(loginText)
        #get password key	
        password=tree.xpath('//input[@type="password"]/@name')[0]
        #get vk value
        vk=tree.xpath('//input[@name="vk"]/@value')[0]
        #wrap post data	
        data={'mobile':self.username,password:self.password,'remember':'on','vk':vk,'submit':'登录'}	
        #encode post data
        data=urllib.urlencode(data)
        #login
        response=opener.open(loginURL,data)
        #<DEBUG>print response.geturl()
        if 'http://login.weibo.cn/' in response.geturl() :
            raise Exception("username or password is wrong")
            logging.info("user :"+self.username+" login sucesses")
        return opener

    #get the users' weibo
    def getWeibo(self,userid)
        weiboid=0
        #weibo list
	weiboList=[]
	#HTTPError may be raised
        req=self.opener.open('http://weibo.cn/'+userid+'?page='+weiboid,timeout=5)
        # if blocked by sina, raise exception
        self.blockedCheck('weibo.cn/'+userid+'?page='+weiboid,req.geturl())
        content=req.read()
	#extract data
	followingList.extend(self.extractFollowing(content))

    def blockedCheck(self,expectedURL,actualURL):
        if expectedURL not in actualURL:
            logging.info('user : '+self.username+' is blocked by Sina')
            raise BlockedException()
	
    def randomRest(self):
        restTime=random.random()*2+5
        time.sleep(restTime)
        return restTime		
	
    def extractFollowingUrl(self,content):
        html=pyquery.PyQuery(content)
        for ele in html('form a'):
            if pyquery.PyQuery(ele).text()==u'下页':
                return pyquery.PyQuery(ele).attr('href')
        return None

    #ATTENTION: Here assume spider follows nobody
    def extractFollowing(self,content):
        pageList=[]
	tree=etree.HTML(content)
        for ele in tree.xpath("//div[@class='c']"):
	    weiboid=ele.get("id").split('_')[1]
            fowardingWeiboId=ele.xpath("//div/span[@class='cmt']/a").text
	    likeNum=ele.xpath("//div/a[text()=u'赞']").text
	    commentNum=ele.xpath("//div/a[text()=u'评论' and last()-1]").text
	    info=ele.xpath("//div/span[@class='ct']").split(u'来自');
	    time=info[0]
	    plantform=[info1]
	    fowardingNum=ele.xpath("//div/a[text()=u'转发']").text
	    //weibo=weiboInfo()
	    print weiboid+","+fowardingWeiboId+","+likeNum+","+commentNum+","+time+","+plantform+","+fowardingNum    
	return pageList

if __name__ == '__main__':
    spider = weiboResolution('18612986170', '18612986170')
    #print spider.extractFollowing('3399558022')
    doc=etree.prise("d://data.html")
    spider.extractFollowing(doc)
